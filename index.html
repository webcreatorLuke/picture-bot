<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Universal Lenses â€” Snap/TikTok-style in the Browser</title>
<style>
  :root{--bg:#0b1020;--panel:#0f1726;--muted:#9fb0cc;}
  body{margin:0; font-family:Inter,system-ui,Roboto,Arial; background:linear-gradient(180deg,#05060a,#0b1020); color:#eaf2ff;}
  .wrap{max-width:1100px;margin:18px auto;padding:18px;border-radius:12px;}
  header{display:flex;align-items:center;gap:12px}
  h1{margin:0;font-size:20px}
  .stage{display:flex;gap:16px;flex-wrap:wrap;margin-top:12px}
  .video-col{flex:1;min-width:360px;background:var(--panel);padding:12px;border-radius:12px}
  #video, #outputCanvas{width:100%;border-radius:10px;background:#000;display:block}
  .controls{width:360px;max-width:100%;background:rgba(255,255,255,0.02);padding:12px;border-radius:12px}
  .controls h3{margin:6px 0 8px;font-size:14px}
  .row{display:flex;gap:8px;flex-wrap:wrap}
  .chip{padding:8px 10px;border-radius:999px;background:transparent;border:1px solid rgba(255,255,255,0.04);cursor:pointer;color:var(--muted);font-weight:600}
  .chip.active{background:linear-gradient(90deg,#7afcff,#7affc7);color:#042026}
  label{display:block;font-size:13px;color:var(--muted);margin-top:8px}
  input[type=range]{width:100%}
  button{padding:8px 10px;border-radius:8px;border:none;background:#3b82f6;color:white;cursor:pointer}
  .small{padding:6px 8px;font-size:13px}
  .effects-list{max-height:220px;overflow:auto;margin-top:8px}
  footer{margin-top:14px;text-align:center;color:var(--muted);font-size:13px}
  .toggle{display:inline-flex;align-items:center;gap:6px}
  .uploader{display:flex;gap:8px;align-items:center}
  .recording{background:#ff4d4d}
</style>
</head>
<body>
  <div class="wrap">
    <header>
      <div style="font-size:28px">ðŸ“¸</div>
      <div>
        <h1>Universal Lenses â€” Snap/TikTok-style (client-side)</h1>
        <div style="color:var(--muted);font-size:13px">Face tracking, masks, stickers, background removal, face-swap, voice effects, particles & recording.</div>
      </div>
    </header>

    <div class="stage">
      <div class="video-col">
        <video id="video" autoplay playsinline muted style="display:none"></video>
        <canvas id="outputCanvas"></canvas>
        <div style="display:flex;gap:8px;margin-top:10px;align-items:center">
          <button id="snapBtn">Snapshot</button>
          <button id="startRecBtn">Start Recording</button>
          <button id="stopRecBtn" disabled>Stop</button>
          <a id="downloadLink" style="display:none"></a>
          <div style="margin-left:auto;color:var(--muted);font-size:13px">Privacy: runs in your browser</div>
        </div>
        <div style="margin-top:10px;display:flex;gap:8px;align-items:center">
          <div class="uploader">
            <input id="faceSwapUpload" type="file" accept="image/*">
            <div style="font-size:13px;color:var(--muted)">Upload face for swap</div>
          </div>
        </div>
      </div>

      <div class="controls">
        <h3>Active Lenses & Options</h3>

        <div class="row" id="lensButtons"></div>

        <label>Intensity <span id="intVal">0.9</span></label>
        <input id="intensity" type="range" min="0" max="2" step="0.01" value="0.9">

        <label>Background</label>
        <div class="row">
          <button class="chip" data-bg="none">None</button>
          <button class="chip" data-bg="blur">Blur</button>
          <button class="chip" data-bg="image">Image</button>
        </div>
        <input id="bgImageUrl" placeholder="Background image URL (for Image option)" style="width:100%;margin-top:6px;padding:8px;border-radius:8px;border:none;background:#07101f;color:#dfefff"/>

        <label>Voice FX</label>
        <div class="row">
          <button class="chip" data-voice="none">None</button>
          <button class="chip" data-voice="pitchUp">Pitch +</button>
          <button class="chip" data-voice="robot">Robot</button>
          <button class="chip" data-voice="echo">Echo</button>
        </div>

        <label>Add-ons</label>
        <div class="row effects-list" id="addons"></div>
        <div style="margin-top:8px">
          <button id="addPluginBtn" class="small">Add plugin (load JSON lens)</button>
        </div>

        <label style="margin-top:10px">Performance</label>
        <div class="row">
          <button class="chip" id="lowPerf">Low</button>
          <button class="chip active" id="medPerf">Med</button>
          <button class="chip" id="highPerf">High</button>
        </div>
      </div>
    </div>

    <footer>
      Want more advanced native-level performance or a lens store? I can outline a server + app build. ðŸ”¥
    </footer>
  </div>

  <!-- MediaPipe FaceMesh & Selfie Segmentation -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
  <!-- Three.js for 3D masks -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.159.0/build/three.min.js"></script>

<script>
/* ============================
   Universal Lenses â€” single file
   Features implemented:
   - Auto camera
   - FaceMesh (landmarks) driven stickers + warps
   - SelfieSegmentation background replacement (none/blur/image)
   - Dog tongue mouth-open trigger
   - Big eyes warp
   - Face swap (upload image)
   - 3D mask example via Three.js texture overlay (simple)
   - Particles overlay
   - WebAudio voice effects (pitch, robot, echo)
   - Recording (video+audio) and download
   - Plugin system (add lens JSON objects)
   ============================ */

const video = document.getElementById('video');
const canvas = document.getElementById('outputCanvas');
const ctx = canvas.getContext('2d', { alpha: false });
const snapBtn = document.getElementById('snapBtn');
const startRecBtn = document.getElementById('startRecBtn');
const stopRecBtn = document.getElementById('stopRecBtn');
const intensityInput = document.getElementById('intensity');
const intVal = document.getElementById('intVal');
const lensButtons = document.getElementById('lensButtons');
const addons = document.getElementById('addons');
const bgButtons = document.querySelectorAll('[data-bg]');
const voiceButtons = document.querySelectorAll('[data-voice]');
const faceSwapUpload = document.getElementById('faceSwapUpload');
const bgImageUrl = document.getElementById('bgImageUrl');
const addPluginBtn = document.getElementById('addPluginBtn');

let width = 640, height = 480;
let currentBgMode = 'none';
let bgImage = null;
let activeLens = null;
let addedPlugins = [];
let localFaceImg = null;

// performance preset (controls model fps/size)
let perf = 'med'; // low, med, high

// voice
let audioContext = null;
let micStreamNode = null;
let voiceMode = 'none';
let recorder; // MediaRecorder for combined stream

// particles state
let particles = [];

// face swap source
let faceSwapImage = null;

/* ---------------------------
   camera start
   --------------------------- */
async function startCamera(){
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { width:1280, height:720, facingMode:'user' }, audio: true });
    video.srcObject = stream;
    // audio graph
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    micStreamNode = audioContext.createMediaStreamSource(stream);
  } catch (e) {
    alert('Camera/microphone error: ' + e.message);
  }
}
startCamera();

/* ---------------------------
   MediaPipe setup
   --------------------------- */
const faceMesh = new FaceMesh.FaceMesh({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
});
faceMesh.setOptions({
  maxNumFaces: 1,
  refineLandmarks: true,
  minDetectionConfidence: 0.6,
  minTrackingConfidence: 0.6
});

const selfieSeg = new SelfieSegmentation.SelfieSegmentation({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`
});
selfieSeg.setOptions({modelSelection:1});

let latestResults = null;
async function onFaceResults(results){
  latestResults = results;
}
faceMesh.onResults(onFaceResults);

let latestSeg = null;
selfieSeg.onResults((r)=> { latestSeg = r; });

const cam = new Camera.Camera(video, {
  onFrame: async () => {
    // send frames at reduced size depending on perf
    await faceMesh.send({image: video});
    await selfieSeg.send({image: video});
  },
  width: 1280,
  height: 720
});
cam.start();

/* ---------------------------
   Lens registry & UI
   --------------------------- */
const lenses = [
  { id:'bigEyes', name:'Big Eyes (warp)', fn: lensBigEyes },
  { id:'dog', name:'Dog Ears & Tongue', fn: lensDog },
  { id:'sunglasses', name:'Sunglasses', fn: lensSunglasses },
  { id:'flower', name:'Flower crown', fn: lensFlower },
  { id:'smooth', name:'Smooth skin', fn: lensSmooth },
  { id:'particles', name:'Particles', fn: lensParticles },
  { id:'faceSwap', name:'Face Swap (upload)', fn: lensFaceSwap },
  { id:'threeMask', name:'3D Mask (example)', fn: lensThreeMask },
  { id:'bigMouth', name:'Big Mouth Warp', fn: lensBigMouth }
];

function buildLensButtons(){
  lensButtons.innerHTML='';
  for (const l of lenses){
    const b = document.createElement('button');
    b.className='chip';
    b.textContent = l.name;
    b.onclick = ()=> {
      document.querySelectorAll('#lensButtons .chip').forEach(c=>c.classList.remove('active'));
      b.classList.add('active');
      activeLens = l.fn;
    };
    lensButtons.appendChild(b);
  }
}
buildLensButtons();

// plugin loader
addPluginBtn.onclick = async ()=>{
  const url = prompt('Enter URL of lens JSON (or cancel):');
  if (!url) return;
  try {
    const res = await fetch(url);
    const j = await res.json();
    // j = { id, name, type, ... } minimal
    // add to plugins UI; actual implementation might include shader code or function body
    addedPlugins.push(j);
    const b = document.createElement('button');
    b.className='chip';
    b.textContent = j.name || j.id || 'plugin';
    b.onclick = ()=> {
      alert('Plugin loaded: ' + (j.name||j.id) + '\nFor custom plugin code, include fn body in the JSON and eval (unsafe).');
    };
    addons.appendChild(b);
  } catch (e) {
    alert('Failed to load plugin: ' + e.message);
  }
};

/* ---------------------------
   Render loop
   --------------------------- */
function renderLoop(){
  requestAnimationFrame(renderLoop);
  if (!latestResults || !latestSeg) return;

  // size canvas by video
  if (video.videoWidth && video.videoHeight){
    if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }
  }

  // draw background (segmentation)
  if (currentBgMode === 'none'){
    ctx.drawImage(video,0,0,canvas.width,canvas.height);
  } else {
    // segmentation mask
    const mask = latestSeg.segmentationMask;
    // draw original to temp
    const tmp = document.createElement('canvas'); tmp.width=canvas.width; tmp.height=canvas.height;
    const tctx = tmp.getContext('2d');
    tctx.drawImage(video,0,0,canvas.width,canvas.height);
    // draw mask
    ctx.clearRect(0,0,canvas.width,canvas.height);
    if (currentBgMode === 'blur'){
      // blur background: draw mask then composite
      // draw background blurred
      ctx.filter = 'blur(10px)';
      ctx.drawImage(video,0,0,canvas.width,canvas.height);
      ctx.filter = 'none';
      // overlay person from tmp using mask as alpha
      ctx.globalCompositeOperation = 'destination-in';
      ctx.drawImage(mask,0,0,canvas.width,canvas.height);
      ctx.globalCompositeOperation = 'destination-over';
      // draw unmasked background (we already have blurred)
    } else if (currentBgMode === 'image'){
      // draw bg image then draw person masked on top
      if (bgImage) ctx.drawImage(bgImage,0,0,canvas.width,canvas.height);
      ctx.globalCompositeOperation = 'destination-in';
      ctx.drawImage(mask,0,0,canvas.width,canvas.height);
      ctx.globalCompositeOperation = 'source-over';
      // now composite person onto bg
      const personCanvas = document.createElement('canvas'); personCanvas.width=canvas.width; personCanvas.height=canvas.height;
      personCanvas.getContext('2d').drawImage(video,0,0,canvas.width,canvas.height);
      ctx.globalCompositeOperation = 'source-over';
      ctx.drawImage(personCanvas,0,0);
    }
  }

  // default: draw camera if not drawn by seg logic
  if (currentBgMode === 'none') {
    // we already drew video
  } else if (currentBgMode === 'blur' ){
    // we need to overlay the person (inverse mask)
    const mask = latestSeg.segmentationMask;
    ctx.globalCompositeOperation = 'destination-in';
    ctx.drawImage(mask,0,0,canvas.width,canvas.height);
    ctx.globalCompositeOperation = 'source-over';
  }

  // draw landmarks debug (optional)
  // drawFaceLandmarks(latestResults.multiFaceLandmarks[0]);

  // apply active lens if present
  if (activeLens && latestResults.multiFaceLandmarks.length > 0) {
    try {
      activeLens(latestResults.multiFaceLandmarks[0]);
    } catch(e) {
      console.error('lens error', e);
    }
  }

  // overlay particles if active
  if (particleOn) drawParticles();
}
requestAnimationFrame(renderLoop);

/* ---------------------------
   Lens implementations
   --------------------------- */
// helper to get landmark in px
function lm(landmarks, i){ return { x:landmarks[i].x * canvas.width, y:landmarks[i].y * canvas.height }; }

function drawFaceLandmarks(landmarks){
  if (!landmarks) return;
  ctx.fillStyle='rgba(0,255,0,0.6)';
  for(let i=0;i<landmarks.length;i+=4){
    const p=lm(landmarks,i);
    ctx.fillRect(p.x-1,p.y-1,3,3);
  }
}

function lensBigEyes(landmarks){
  // simple approach: draw scaled opaque white ellipses over eyes to simulate big eyes
  const left = lm(landmarks, 33); // approximate left
  const right = lm(landmarks, 263);
  const scale = parseFloat(intensityInput.value);
  const rx = Math.max(18, 40 * scale);
  const ry = Math.max(10, 24 * scale);
  ctx.fillStyle = 'rgba(255,255,255,0.45)';
  ctx.beginPath(); ctx.ellipse(left.x, left.y, rx, ry, 0, 0, Math.PI*2); ctx.fill();
  ctx.beginPath(); ctx.ellipse(right.x, right.y, rx, ry, 0, 0, Math.PI*2); ctx.fill();
}

function lensDog(landmarks){
  // draw ears and nose stickers; open mouth -> tongue
  const nose = lm(landmarks, 1);
  const leftEar = lm(landmarks, 10);
  const rightEar = lm(landmarks, 338);
  // ears (example images hosted) - small images included via links
  drawCachedImage('https://i.imgur.com/CzXTtJV.png', leftEar.x - 140, leftEar.y - 240, 280, 220);
  drawCachedImage('https://i.imgur.com/CzXTtJV.png', rightEar.x - 140, rightEar.y - 240, 280, 220);
  drawCachedImage('https://i.imgur.com/5qH6YQf.png', nose.x - 60, nose.y - 20, 120, 120);

  // detect mouth open - use landmarks 13 (upper lip) and 14 (lower lip)
  const upperLip = lm(landmarks,13);
  const lowerLip = lm(landmarks,14);
  const mouthOpen = (lowerLip.y - upperLip.y) > (canvas.height * 0.03) * parseFloat(intensityInput.value);
  if (mouthOpen) {
    drawCachedImage('https://i.imgur.com/7yK1NfW.png', nose.x - 60, nose.y + 20, 120, 150); // tongue image
  }
}

function lensSunglasses(landmarks){
  const left = lm(landmarks,33);
  const right = lm(landmarks,263);
  const w = (right.x - left.x) * 2.0 * parseFloat(intensityInput.value);
  const x = left.x - w*0.2;
  const y = left.y - 60;
  drawCachedImage('https://i.imgur.com/PpmE2gj.png', x, y, w, w*0.35);
}

function lensFlower(landmarks){
  const forehead = lm(landmarks,10);
  drawCachedImage('https://i.imgur.com/vxLqf0u.png', forehead.x - 200, forehead.y - 200, 420, 220);
}

function lensSmooth(landmarks){
  // simple skin smoothing: draw blurred version of canvas on top with low alpha over face region
  ctx.save();
  ctx.filter = 'blur(6px)';
  ctx.globalAlpha = 0.25;
  ctx.drawImage(canvas, 0, 0);
  ctx.restore();
  ctx.globalAlpha = 1.0;
}

let particleOn=false;
function lensParticles(landmarks){
  particleOn=true;
  // spawn particles at forehead
  const top = lm(landmarks,10);
  for (let i=0;i<3;i++){
    particles.push({ x: top.x + (Math.random()-0.5)*30, y: top.y-10, vx:(Math.random()-0.5)*1.4, vy:-1.2 - Math.random()*1.2, life:80, size:6+Math.random()*8, hue: Math.floor(Math.random()*360) });
  }
}

function lensFaceSwap(landmarks){
  if (!faceSwapImage) {
    ctx.fillStyle='rgba(255,255,255,0.02)';
    ctx.fillRect(10,10,150,40);
    ctx.fillStyle='#9fb0cc';
    ctx.fillText('Upload a face image to swap', 18, 36);
    return;
  }
  // crude swap: draw faceSwapImage centered at landmark 1 with scale based on face bounding box
  const left = lm(landmarks, 130);
  const right = lm(landmarks, 359);
  const top = lm(landmarks, 10);
  const bottom = lm(landmarks, 152);
  const w = Math.abs(right.x - left.x)*1.6;
  const h = Math.abs(bottom.y - top.y)*1.7;
  ctx.save();
  // simple blend
  ctx.globalAlpha = 0.95;
  ctx.drawImage(faceSwapImage, (left.x+right.x)/2 - w/2, top.y - h*0.12, w, h);
  ctx.globalAlpha = 1.0;
  ctx.restore();
}

let threeInitialized=false;
function lensThreeMask(landmarks){
  // For demo: overlay a 3D texture at forehead using 2D draw (real Three.js scene would be separate canvas)
  if (!threeInitialized) initThreeOverlay();
  const top = lm(landmarks,10);
  ctx.save();
  ctx.globalAlpha = 0.95;
  drawCachedImage('https://i.imgur.com/0bXQXk6.png', top.x - 120, top.y - 200, 240, 240);
  ctx.restore();
}

function lensBigMouth(landmarks){
  // enlarge mouth region
  const mouthCenter = lm(landmarks,13);
  const mouthW = Math.abs(lm(landmarks,61).x - lm(landmarks,291).x) * 2.2;
  const mouthH = Math.abs(lm(landmarks,13).y - lm(landmarks,14).y) * 4.0;
  // sample region and draw scaled
  try {
    const sx = mouthCenter.x - mouthW/3;
    const sy = mouthCenter.y - mouthH/3;
    const tw = mouthW;
    const th = mouthH;
    ctx.save();
    const tmp = document.createElement('canvas'); tmp.width=tw; tmp.height=th;
    tmp.getContext('2d').drawImage(canvas, sx, sy, tw, th, 0, 0, tw, th);
    ctx.translate(mouthCenter.x, mouthCenter.y);
    ctx.scale(1.1 + parseFloat(intensityInput.value)*0.6, 1.3 + parseFloat(intensityInput.value)*0.8);
    ctx.drawImage(tmp, -tw/2, -th/2, tw, th);
    ctx.restore();
  } catch(e){}
}

/* ---------------------------
   Particles engine
   --------------------------- */
function drawParticles(){
  for (let i = particles.length - 1; i >= 0; i--){
    const p = particles[i];
    p.x += p.vx;
    p.y += p.vy;
    p.vy += 0.03;
    p.life--;
    ctx.beginPath();
    ctx.fillStyle = 'hsla(' + p.hue + ',80%,' + (50 + (p.life%20)) + '%,0.9)';
    ctx.arc(p.x, p.y, Math.max(1, p.size * (p.life/80)), 0, Math.PI*2);
    ctx.fill();
    if (p.life <= 0 || p.y > canvas.height + 50) particles.splice(i,1);
  }
}

/* ---------------------------
   utilities: image caching, draw
   --------------------------- */
const imageCache = {};
function drawCachedImage(url, x, y, w, h){
  if (!url) return;
  if (!imageCache[url]) {
    const img = new Image();
    img.crossOrigin = 'anonymous';
    img.onload = ()=> { imageCache[url] = img; };
    img.src = url;
    imageCache[url] = null;
    return;
  }
  const img = imageCache[url];
  if (!img) return;
  ctx.drawImage(img, x, y, w, h);
}

/* ---------------------------
   Face swap upload handler
   --------------------------- */
faceSwapUpload.addEventListener('change', (ev)=>{
  const f = ev.target.files[0];
  if (!f) return;
  const reader = new FileReader();
  reader.onload = (e)=>{
    const img = new Image();
    img.onload = ()=> {
      faceSwapImage = img;
    };
    img.src = e.target.result;
  };
  reader.readAsDataURL(f);
});

/* ---------------------------
   Background control
   --------------------------- */
bgButtons.forEach(b=>{
  b.addEventListener('click', ()=>{
    bgButtons.forEach(x=>x.classList.remove('active'));
    b.classList.add('active');
    currentBgMode = b.dataset.bg;
    if (currentBgMode === 'image') {
      const url = bgImageUrl.value.trim();
      if (url) {
        const img = new Image(); img.crossOrigin='anonymous';
        img.onload = ()=> { bgImage = img; };
        img.src = url;
      } else {
        bgImage = null;
      }
    }
  });
});
document.querySelector('[data-bg="none"]').classList.add('active');

/* ---------------------------
   Voice effects (simple)
   --------------------------- */
voiceButtons.forEach(b=>{
  b.addEventListener('click', ()=> {
    voiceButtons.forEach(x=>x.classList.remove('active'));
    b.classList.add('active');
    voiceMode = b.dataset.voice;
    setupVoiceGraph();
  });
});

function setupVoiceGraph(){
  if (!audioContext || !micStreamNode) return;
  // disconnect existing
  try { audioContext.close(); } catch(e){}
  audioContext = new (window.AudioContext || window.webkitAudioContext)();
  micStreamNode = audioContext.createMediaStreamSource(video.srcObject);
  // use simple fx chains
  const dest = audioContext.createMediaStreamDestination();
  let source = micStreamNode;
  if (voiceMode === 'none') {
    source.connect(dest);
  } else if (voiceMode === 'pitchUp'){
    // pitch shift via playbackRate not trivial; simple detune via playbackRate on offline buffer (approx). We'll approximate with a DelayNode modulator for fun
    const delay = audioContext.createDelay(); delay.delayTime.value = 0.03;
    const gain = audioContext.createGain(); gain.gain.value = 0.9;
    source.connect(delay);
    delay.connect(gain);
    gain.connect(dest);
  } else if (voiceMode === 'robot'){
    const node = audioContext.createBiquadFilter(); node.type='highpass'; node.frequency.value = 800;
    source.connect(node);
    node.connect(dest);
  } else if (voiceMode === 'echo'){
    const delay = audioContext.createDelay(); delay.delayTime.value = 0.25;
    const fb = audioContext.createGain(); fb.gain.value = 0.35;
    source.connect(delay);
    delay.connect(fb);
    fb.connect(delay);
    delay.connect(dest);
    source.connect(dest);
  }
  // create MediaRecorder for dest.stream when recording
  recordingDestStream = dest.stream;
}

/* ---------------------------
   Recording
   --------------------------- */
let mixedStream = null;
let mediaRecorder = null;
let recordedChunks = [];
let recordingDestStream = null;

startRecBtn.addEventListener('click', async ()=>{
  // prepare audio graph
  setupVoiceGraph();
  // capture canvas as stream + audio
  const canvasStream = canvas.captureStream(30); // 30 fps
  const audioStream = (recordingDestStream && recordingDestStream.getAudioTracks().length) ? recordingDestStream : (video.srcObject ? new MediaStream(video.srcObject.getAudioTracks()) : null);
  if (audioStream) {
    mixedStream = new MediaStream([...canvasStream.getVideoTracks(), ...audioStream.getAudioTracks()]);
  } else {
    mixedStream = canvasStream;
  }
  recordedChunks = [];
  mediaRecorder = new MediaRecorder(mixedStream, { mimeType: 'video/webm;codecs=vp9' });
  mediaRecorder.ondataavailable = (e)=> { if (e.data.size>0) recordedChunks.push(e.data); };
  mediaRecorder.onstop = ()=> {
    const blob = new Blob(recordedChunks, { type: 'video/webm' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url; a.download = 'lens_recording.webm'; a.textContent = 'Download recording';
    a.style.display='inline-block'; a.style.marginLeft='12px'; document.querySelector('.video-col').appendChild(a);
  };
  mediaRecorder.start();
  startRecBtn.disabled = true; stopRecBtn.disabled = false; startRecBtn.classList.add('recording');
});

stopRecBtn.addEventListener('click', ()=>{
  mediaRecorder && mediaRecorder.stop();
  startRecBtn.disabled = false; stopRecBtn.disabled = true; startRecBtn.classList.remove('recording');
});

/* ---------------------------
   Snapshot
   --------------------------- */
snapBtn.addEventListener('click', ()=>{
  const data = canvas.toDataURL('image/png');
  const a = document.createElement('a');
  a.href = data; a.download = 'snapshot.png'; a.click();
});

/* ---------------------------
   Performance presets (stub)
   --------------------------- */
document.getElementById('lowPerf').addEventListener('click', ()=> setPerf('low'));
document.getElementById('medPerf').addEventListener('click', ()=> setPerf('med'));
document.getElementById('highPerf').addEventListener('click', ()=> setPerf('high'));
function setPerf(p){ perf=p; document.querySelectorAll('#lensButtons .chip').forEach(c=>c.classList.remove('active')); document.getElementById('medPerf').classList.toggle('active', perf==='med'); }

/* ---------------------------
   Simple 3D overlay init (placeholder)
   --------------------------- */
function initThreeOverlay(){
  /* For a real 3D mask you'd create a Three.js scene, map a face mesh geometry to MediaPipe landmarks,
     then render to a separate WebGL canvas and composite. For demo we use a static PNG overlay in lensThreeMask. */
  threeInitialized = true;
}

/* ---------------------------
   UI updates
   --------------------------- */
intensityInput.addEventListener('input', ()=> intVal.textContent = intensityInput.value);

/* ---------------------------
   End of app
   --------------------------- */

</script>
</body>
</html>
